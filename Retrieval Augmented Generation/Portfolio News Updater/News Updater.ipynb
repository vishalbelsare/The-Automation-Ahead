{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e56619e4",
      "metadata": {},
      "source": [
        "# Portfolio Material News Updater  \n",
        "\n",
        "Welcome to the **Material News Updater** tutorial. By the end of this notebook you will be able to:\n",
        "\n",
        "1. **Collect** fresh articles from a curated list of financial-news RSS feeds.\n",
        "2. **Embed** those stories in a Chroma vector database with OpenAI embeddings.\n",
        "3. **Query** the database with GPT-4.1-mini to surface *material* news for a portfolio of stocks.\n",
        "4. **Summarize** the individual stock news breifs into a concise portfolio brief.\n",
        "5. **Email** yourself a concise morning briefing—fully automated.\n",
        "\n",
        "You’ll practise:\n",
        "\n",
        "* Working with RSS feeds.\n",
        "* Turning raw text into embeddings using LangChain + OpenAI.\n",
        "* Building a Retrieval-Augmented Generation (RAG) chain.\n",
        "* Packaging results for convenient distribution.\n",
        "\n",
        "**Prerequisites**  \n",
        "• Python ≥ 3.11 (Conda or venv).  \n",
        "• OpenAI and Yahoo Mail credentials stored in a `.env` file.\n",
        "\n",
        "You can also run this notebook via a Google Colab here:\n",
        "\n",
        "---\n",
        "\n",
        "Let’s start by loading the RSS catalogue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8723b736",
      "metadata": {},
      "source": [
        "## 1. Load RSS sources\n",
        "\n",
        "`news_rss.json` contains a simple list of feed URLs plus some lightweight metadata.  \n",
        "The next cell just deserialises that file into Python so we can iterate over it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e43e0230",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('news_rss.json', 'r') as file:\n",
        "    rss_json = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5694b04f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below line to install the feedparser package\n",
        "# !pip install feedparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958f0e4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "rss_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a83c9bbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import feedparser\n",
        "import time\n",
        "\n",
        "feeds = []\n",
        "\n",
        "for rss_dict in rss_json:\n",
        "    rss_url = rss_dict['rss']\n",
        "    source = rss_dict['source']\n",
        "    type = rss_dict['type']\n",
        "    feed = feedparser.parse(rss_url)\n",
        "    feed_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))\n",
        "    feed_dict = {\n",
        "        'source':source,\n",
        "        'type':type,\n",
        "        'feed':feed,\n",
        "        'time_pulled':feed_time\n",
        "    }\n",
        "    feeds.append(feed_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86a463d",
      "metadata": {},
      "source": [
        "## 2. Embed stories and build the vector store\n",
        "  \n",
        "Here we walk through each RSS entry, keep the entire article intact (because they’re short), and prepare a list of `documents` that we’ll feed into Chroma. Each document carries metadata—`title`, `source`, the time we pulled it, and a high-level `news_type` tag—for easier filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8ec97ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Create full documents from entries without splitting\n",
        "documents = []\n",
        "for rss_feed in feeds:\n",
        "    try:\n",
        "        for entry in rss_feed['feed']['entries']: \n",
        "            title = entry['title']\n",
        "            entry_content = str(entry)\n",
        "            documents.append({\"content\": entry_content, \"metadata\": {\"title\":title,\"source\": rss_feed[\"source\"], \"time_pulled\": rss_feed[\"time_pulled\"], \"news_type\":rss_feed['type']}})\n",
        "    except Exception as e:\n",
        "        print(f'An error - {e} occured for {entry}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64efc379",
      "metadata": {},
      "source": [
        "### Why batch embeddings?\n",
        "\n",
        "OpenAI’s embedding endpoint caps *each request* at **300 k tokens**. The helper below measures every document, adds them to a running total, and starts a new batch whenever the next doc would tip us over the limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "929c60f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash and run the below if you need to install the tiktoken package\n",
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3895a4bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def batch_docs(documents, model='text-embedding-3-small', token_limit=300000):\n",
        "    import tiktoken\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    \n",
        "    batches = []\n",
        "    current_tokens = 0\n",
        "    current_docs = []\n",
        "\n",
        "    for document in documents:\n",
        "        tokens = len(encoding.encode(document[\"content\"]))\n",
        "        \n",
        "        if tokens > token_limit:\n",
        "            raise ValueError(f\"Single document exceeds token limit: {tokens} tokens\")\n",
        "\n",
        "        if current_tokens + tokens > token_limit:\n",
        "            batches.append(current_docs)\n",
        "            current_docs = [document]\n",
        "            current_tokens = tokens\n",
        "        else:\n",
        "            current_docs.append(document)\n",
        "            current_tokens += tokens\n",
        "\n",
        "    if current_docs:\n",
        "        batches.append(current_docs)\n",
        "\n",
        "    return batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "9796a370",
      "metadata": {},
      "outputs": [],
      "source": [
        "batches = batch_docs(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "65635ab2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma  # Example vector store\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model and vector store\n",
        "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "vector_store = Chroma(collection_name='rss_news_feeds', embedding_function=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bb81c541",
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in batches:\n",
        "    texts = [doc[\"content\"] for doc in batch]\n",
        "    metadatas = [doc[\"metadata\"] for doc in batch]\n",
        "    vector_store.add_texts(texts, metadatas=metadatas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371c3dae",
      "metadata": {},
      "source": [
        "## 3. Craft the system prompt\n",
        "\n",
        "This prompt underpins our retrieval chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2a9a6d25",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = (\n",
        "    \"You are an assistant designed to search through news feeds and find the most relevant news based on a prompt. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't have enough information to infer an answer, say that you dont have enough information to answer the question.\"\n",
        "    \"Each document contains the meta data which has the source, news type and pulled date. If you have two stories from different sources that\"\n",
        "    \" appear to be about the same story prioritize the one with the ealier published time.\"\n",
        "    \"Keep the answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7adf4713",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below line if you need to install yfinance\n",
        "#!pip install yfinance # We will use yfinance to give some more context about portfolio companies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099749a0",
      "metadata": {},
      "source": [
        "## 4. Create the RAG Chain\n",
        "\n",
        "Here we put all the components together for our RAG workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d2e3bf2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, qa_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rag_over_portfolio",
      "metadata": {},
      "source": [
        "## 5. RAG over the portfolio\n",
        "\n",
        "For each ticker we:\n",
        "1. Pull a short business description from `yfinance` for extra context.  \n",
        "2. Ask the RAG chain which news **published today** might move the stock price.  \n",
        "3. Return a markdown snippet we’ll aggregate later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "98482519",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing import List\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# 1. Function to summarize news for a given ticker\n",
        "def summarize_ticker(ticker: str) -> str:\n",
        "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "    info  = yf.Ticker(ticker).info\n",
        "    company     = info.get(\"longName\", ticker)\n",
        "    description = info.get(\"longBusinessSummary\", \"\")\n",
        "    query = (\n",
        "        f\"Today's date is {today}. You MUST only reference news published either today or yesterday. News published any other day is unacceptable!\\n\\n\"\n",
        "        f\"Here is a description of {company}: {description}\\n\\n\"\n",
        "        f\"Which news stories published either today or yesterday are most likely to have a material impact on {company}'s stock? If there isnt anything material, say so.\\n\\n\"\n",
        "        \"Include citations. Remember news published any other day is unacceptable!\"\n",
        "    )\n",
        "    result = rag_chain.invoke({\"input\": query})\n",
        "    return f\"{ticker} – {company}:\\n{result}\\n\"\n",
        "\n",
        "# 2. Generate per-ticker summaries\n",
        "tickers = [\"AAPL\",\"MSFT\",\"NVDA\",\"JNJ\",\"UNH\",\"JPM\",\"V\",\"PG\",\"KO\",\"XOM\"]\n",
        "summaries = [summarize_ticker(t) for t in tickers]\n",
        "\n",
        "# 3. Wrap into Documents for summarization chain\n",
        "docs = [\n",
        "    Document(page_content=s, metadata={\"ticker\": s.split(\"–\")[0]})\n",
        "    for s in summaries\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rollup_brief",
      "metadata": {},
      "source": [
        "## 6. Roll-up briefing\n",
        "\n",
        "A second LLM pass condenses the individual blurbs into a single portfolio brief, formatted in Markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff2cebf",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_portfolio_breif(summary_docs:List[Document],model='gpt-4o') -> str:\n",
        "    input = f\"\"\"Use your expert ability to sythesize the following portfolio stock news briefs \\\n",
        "     to extract material information related to all stocks in the portfolio. Output your answer \\\n",
        "     in markdown format (not a markdown codebox). Make sure you provide in-context citations for articles that back up your highlights. \\\n",
        "     Here are the news briefs: {str(summary_docs)}\"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert financial analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": input}\n",
        "        ],\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "# 3. Create and run a map-reduce summarization chain\n",
        "portfolio_brief = create_portfolio_breif(docs)\n",
        "\n",
        "print(portfolio_brief)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae218502",
      "metadata": {},
      "source": [
        "## 7. Deliver the brief\n",
        "\n",
        "We convert the Markdown to HTML and send it via Yahoo SMTP.  \n",
        "Make sure you’ve set `YAHOO_EMAIL`, `YAHOO_APP_PASSWORD`, and `TO_EMAIL` in your environment *before* running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5291d3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the bwlow line if you need to install the markdown package\n",
        "#!pip install markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a11ab1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import smtplib\n",
        "import markdown\n",
        "from email.message import EmailMessage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables (e.g. from a .env file)\n",
        "load_dotenv()\n",
        "\n",
        "YAHOO_EMAIL        = os.environ['YAHOO_EMAIL']\n",
        "YAHOO_APP_PASSWORD = os.environ['YAHOO_APP_PASSWORD']\n",
        "TO_EMAIL           = os.environ['TO_EMAIL']\n",
        "\n",
        "def send_yahoo_email(subject: str, body_markdown: str):\n",
        "    \"\"\"Send an HTML email via Yahoo SMTP (STARTTLS on port 587).\"\"\"\n",
        "    # Build the email\n",
        "    msg = EmailMessage()\n",
        "    msg['Subject'] = subject\n",
        "    msg['From']    = YAHOO_EMAIL\n",
        "    msg['To']      = TO_EMAIL\n",
        "\n",
        "    # Convert Markdown to HTML\n",
        "    html_body = markdown.markdown(body_markdown)\n",
        "    msg.set_content(\"This email contains HTML only.\", subtype=\"plain\")\n",
        "    msg.add_alternative(html_body, subtype=\"html\")\n",
        "\n",
        "    try:\n",
        "        # Connect, secure with STARTTLS, login, send\n",
        "        with smtplib.SMTP('smtp.mail.yahoo.com', 587, timeout=30) as server:\n",
        "            server.starttls()\n",
        "            server.login(YAHOO_EMAIL, YAHOO_APP_PASSWORD)\n",
        "            server.send_message(msg)\n",
        "        print(f\"\\n✅ Email sent successfully to {TO_EMAIL}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Failed to send: {e}\")\n",
        "\n",
        "# Example invocation using your portfolio brief\n",
        "send_yahoo_email(\"Morning Brief\", portfolio_brief)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
