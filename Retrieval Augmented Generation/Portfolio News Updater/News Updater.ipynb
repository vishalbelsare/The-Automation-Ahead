{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e56619e4",
      "metadata": {},
      "source": [
        "# Portfolio Material News Updater  \n",
        "\n",
        "Welcome to the **Material News Updater** tutorial. By the end of this notebook you will be able to:\n",
        "\n",
        "1. **Collect** fresh articles from a curated list of financial-news RSS feeds.\n",
        "2. **Embed** those stories in a Chroma vector database with OpenAI embeddings.\n",
        "3. **Query** the database with GPT-4.1-mini to surface *material* news for a portfolio of stocks.\n",
        "4. **Summarize** the individual stock news breifs into a concise portfolio brief.\n",
        "5. **Email** yourself a concise morning briefing—fully automated.\n",
        "\n",
        "You’ll practise:\n",
        "\n",
        "* Working with RSS feeds.\n",
        "* Turning raw text into embeddings using LangChain + OpenAI.\n",
        "* Building a Retrieval-Augmented Generation (RAG) chain.\n",
        "* Packaging results for convenient distribution.\n",
        "\n",
        "**Prerequisites**  \n",
        "• Python ≥ 3.11 (Conda or venv).  \n",
        "• OpenAI API key and Yahoo Mail credentials stored in a `.env` file (use the .env.example template and remove the .example suffix).\n",
        "\n",
        "# OpenAI Account Setup\n",
        "* Create an OpenAI Platform Account – Go to [platform.openai.com](https://platform.openai.com/docs/overview) and follow the prompts to sign up.\n",
        "* Generate Your API Key – After signing in, navigate to the API keys page to create a new secret key.\n",
        "\n",
        "# Yahoo Account Setup\n",
        "This example uses **Yahoo Mail** to send the morning brief because it supports SMTP with `STARTTLS`, making it easy to integrate using the stmplib python library for sending emails.\n",
        "\n",
        "⚠️ **WARNING:** For security and privacy reasons, we strongly recommend using a **dedicated “junk” Yahoo account** for this project. Do **not** use your personal or sensitive email address as your sending email. The TO_EMAIL, which is the email for the brief to be sent to can be any email as this does not require sensitive information. \n",
        "\n",
        "To set it up:\n",
        "- [Create a new Yahoo email account](https://login.yahoo.com/account/create)\n",
        "- [Generate an app password](https://help.yahoo.com/kb/SLN15241.html?guccounter=1) to use instead of your actual login\n",
        "\n",
        "You can also run this notebook via a Google Colab here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1nEkt2ivAlU2XVU7AkyQG4Q-rMat7UcX8?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "Let’s start by loading the RSS catalogue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8723b736",
      "metadata": {},
      "source": [
        "## 1. Load RSS sources\n",
        "\n",
        "`news_rss.json` contains a simple list of feed URLs plus some lightweight metadata.  \n",
        "The next cell just deserialises that file into Python so we can iterate over it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "e43e0230",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('news_rss.json', 'r') as file:\n",
        "    rss_json = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5694b04f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below line to install the feedparser package\n",
        "# !pip install feedparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "a83c9bbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import feedparser\n",
        "import time\n",
        "\n",
        "feeds = []\n",
        "\n",
        "for rss_dict in rss_json:\n",
        "    rss_url = rss_dict['rss']\n",
        "    source = rss_dict['source']\n",
        "    news_type = rss_dict['type']\n",
        "    feed = feedparser.parse(rss_url)\n",
        "    feed_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))\n",
        "    feed_dict = {\n",
        "        'source':source,\n",
        "        'type':news_type,\n",
        "        'feed':feed,\n",
        "        'time_pulled':feed_time\n",
        "    }\n",
        "    feeds.append(feed_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86a463d",
      "metadata": {},
      "source": [
        "## 2. Embed stories and build the vector store\n",
        "  \n",
        "Here we walk through each RSS entry, keep the entire article intact (because they’re short), and prepare a list of `documents` that we’ll feed into Chroma. Each document carries metadata—`title`, `source`, the time we pulled it, and a high-level `news_type` tag—for easier filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8ec97ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Create full documents from entries without splitting\n",
        "documents = []\n",
        "for rss_feed in feeds:\n",
        "    try:\n",
        "        for entry in rss_feed['feed']['entries']: \n",
        "            title = entry['title']\n",
        "            entry_content = str(entry)\n",
        "            documents.append({\"content\": entry_content, \"metadata\": {\"title\":title,\"source\": rss_feed[\"source\"], \"time_pulled\": rss_feed[\"time_pulled\"], \"news_type\":rss_feed['type']}})\n",
        "    except Exception as e:\n",
        "        print(f'An error - {e} occured for {entry}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64efc379",
      "metadata": {},
      "source": [
        "### Batch The Embeddings\n",
        "\n",
        "OpenAI’s embedding endpoint caps *each request* at **300 k tokens**. The helper below measures every document, adds them to a running total, and starts a new batch whenever the next doc would tip us over the limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "929c60f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash and run the below if you need to install the tiktoken package\n",
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "3895a4bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def batch_docs(documents, model='text-embedding-3-small', token_limit=300000):\n",
        "    import tiktoken\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    \n",
        "    batches = []\n",
        "    current_tokens = 0\n",
        "    current_docs = []\n",
        "\n",
        "    for document in documents:\n",
        "        tokens = len(encoding.encode(document[\"content\"]))\n",
        "        \n",
        "        if tokens > token_limit:\n",
        "            raise ValueError(f\"Single document exceeds token limit: {tokens} tokens\")\n",
        "\n",
        "        if current_tokens + tokens > token_limit:\n",
        "            batches.append(current_docs)\n",
        "            current_docs = [document]\n",
        "            current_tokens = tokens\n",
        "        else:\n",
        "            current_docs.append(document)\n",
        "            current_tokens += tokens\n",
        "\n",
        "    if current_docs:\n",
        "        batches.append(current_docs)\n",
        "\n",
        "    return batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "9796a370",
      "metadata": {},
      "outputs": [],
      "source": [
        "batches = batch_docs(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885b1d07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below to install chromadb\n",
        "# !pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "65635ab2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model and vector store\n",
        "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "vector_store = Chroma(collection_name='rss_news_feeds', embedding_function=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "bb81c541",
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in batches:\n",
        "    texts = [doc[\"content\"] for doc in batch]\n",
        "    metadatas = [doc[\"metadata\"] for doc in batch]\n",
        "    vector_store.add_texts(texts, metadatas=metadatas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371c3dae",
      "metadata": {},
      "source": [
        "## 3. Craft the system prompt\n",
        "\n",
        "This prompt underpins our retrieval chain. We must include the \"{context}\" variable in the prompt as this will bring in the relevant news articles based on our query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "2a9a6d25",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = (\n",
        "    \"You are an assistant designed to search through news feeds and find the most relevant news based on a prompt. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't have enough information to infer an answer, say that you dont have enough information to answer the question.\"\n",
        "    \"Each document contains the meta data which has the source, news type and pulled date. If you have two stories from different sources that\"\n",
        "    \" appear to be about the same story prioritize the one with the ealier published time.\"\n",
        "    \"Keep the answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7adf4713",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below line if you need to install yfinance\n",
        "#!pip install yfinance # We will use yfinance to give some more context about portfolio companies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099749a0",
      "metadata": {},
      "source": [
        "## 4. Create the RAG Chain\n",
        "\n",
        "Here we put all the components together for our RAG workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bec75a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the below to install langchain_community and langchain_openai\n",
        "#!pip install langchain_community\n",
        "#!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "d2e3bf2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from datetime import datetime\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, qa_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rag_over_portfolio",
      "metadata": {},
      "source": [
        "## 5. Create material news summaries for each company\n",
        "\n",
        "For each ticker we:\n",
        "1. Pull a short business description from `yfinance` for extra context.  \n",
        "2. Ask the RAG chain which news **published today** might have a material effect on the stock prices.  \n",
        "3. Put each answer in a document for us to aggregate into our portfolio brief later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "98482519",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing import List\n",
        "from openai import OpenAI\n",
        "import yfinance as yf\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# 1. Function to summarize news for a given ticker\n",
        "def summarize_ticker(ticker: str) -> str:\n",
        "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "    info  = yf.Ticker(ticker).info\n",
        "    company     = info.get(\"longName\", ticker)\n",
        "    description = info.get(\"longBusinessSummary\", \"\")\n",
        "    query = (\n",
        "        f\"Today's date is {today}. You MUST only reference news published either today or yesterday. News published any other day is unacceptable!\\n\\n\"\n",
        "        f\"Here is a description of {company}: {description}\\n\\n\"\n",
        "        f\"Which news stories published either today or yesterday are most likely to have a material impact on {company}'s stock? If there isnt anything material, say so.\\n\\n\"\n",
        "        \"Include citations. Remember news published any other day is unacceptable!\"\n",
        "    )\n",
        "    result = rag_chain.invoke({\"input\": query})\n",
        "    return f\"{ticker} – {company}:\\n{result}\\n\"\n",
        "\n",
        "# 2. Generate per-ticker summaries\n",
        "tickers = [\"AAPL\",\"MSFT\",\"NVDA\",\"JNJ\",\"UNH\",\"JPM\",\"V\",\"PG\",\"KO\",\"XOM\"]\n",
        "summaries = [summarize_ticker(t) for t in tickers]\n",
        "\n",
        "# 3. Wrap into Documents for summarization chain\n",
        "docs = [\n",
        "    Document(page_content=s, metadata={\"ticker\": s.split(\"–\")[0]})\n",
        "    for s in summaries\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rollup_brief",
      "metadata": {},
      "source": [
        "## 6. Roll-up briefing\n",
        "\n",
        "A second LLM pass condenses the individual blurbs into a single portfolio brief, formatted in Markdown which we can easily convert to html for the email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "aff2cebf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## AAPL\n",
            "- **Apple is planning to introduce premium-priced folding iPhones starting next year**. Analyst Kuo from TF International Securities highlighted this potential new product line, which could influence future revenue and market perception as Apple competes in the folding smartphone market (Source: CNBC, [June 18, 2025](https://www.cnbc.com/2025/06/18/folding-iphone-apple.html)).\n",
            "- **A bearish options trade has been noted on Apple as the tech giant struggles.** Options trader Tony Zhang has pointed out signs of vulnerability in Apple's stock, possibly affecting investor sentiment and causing fluctuations in Apple's stock price (Source: CNBC, [June 18, 2025](https://www.cnbc.com/2025/06/18/a-bearish-options-trade-on-apple-as-the-tech-giant-struggles.html)).\n",
            "\n",
            "*Explanation*: The potential launch of a premium folding iPhone signifies Apple's entry into an innovative market, which could drive revenue growth if the product gains popularity. Meanwhile, bearish options indicate that some traders foresee challenges or a downturn in Apple's near-term stock performance.\n",
            "\n",
            "## MSFT\n",
            "- **Microsoft plans to cut thousands of jobs, focusing on sales positions**, as part of efforts to manage costs while investing heavily in artificial intelligence (Source: Bloomberg, [June 18, 2025](https://www.bloomberg.com/news/articles/2025-06-18/microsoft-planning-thousands-more-job-cuts-aimed-at-salespeople)).\n",
            "- **The Wall Street Journal confirms the workforce reduction at Microsoft linked to AI investment**, indicating ongoing adjustments and restructuring closely tied to AI business priorities (Source: WSJ, [June 18, 2025](https://www.wsj.com/tech/microsoft-layoffs-sales-ai-25638cab?mod=rss_Technology)).\n",
            "\n",
            "*Explanation*: These moves reflect Microsoft's strategic focus on AI, which can lead to initial cost-cutting through job reductions but may enhance profitability and competitive stance if AI ventures succeed. However, such restructuring also presents risks like impact on employee morale or potential operational disruptions.\n",
            "\n",
            "## NVDA\n",
            "- There is no material news affecting NVIDIA Corporation's stock from June 17 or June 18, 2025.\n",
            "\n",
            "*Explanation*: Lack of current impactful news means NVIDIA's stock should remain largely driven by previous performance data and broader market conditions.\n",
            "\n",
            "## JNJ\n",
            "- There is no material news affecting Johnson & Johnson's stock from June 17 or June 18, 2025.\n",
            "\n",
            "*Explanation*: Without new impactful information, Johnson & Johnson's stock performance is likely influenced by longer-term business factors and existing market trends.\n",
            "\n",
            "## UNH\n",
            "- **Wall Street Journal highlights that UnitedHealth investors demand more transparency**, reflecting detachment in investor trust after previously consistent earnings beats (Source: WSJ, [June 18, 2025](https://www.wsj.com/health/healthcare/its-time-for-unitedhealth-to-get-transparent-with-its-accounting-but-will-it-4d7ef693?mod=rss_markets_main)).\n",
            "\n",
            "*Explanation*: This demand for transparency could pressure UnitedHealth to alter disclosure practices, affecting investor perceptions and potentially stock volatility if transparency issues remain unaddressed.\n",
            "\n",
            "## JPM\n",
            "- **JPMorgan is set to increase the annual fee on its Sapphire Reserve credit card to $795**, indicating a push into the premium credit card market that might influence consumer banking revenue (Sources: CNBC, [June 17, 2025](https://www.cnbc.com/2025/06/17/chase-sapphire-reserve-credit-card-new-perks-fee.html), Bloomberg, [June 17, 2025](https://www.bloomberg.com/news/articles/2025-06-17/jpmorgan-hikes-sapphire-reserve-fee-to-795-in-card-overhaul)).\n",
            "- **JPMorgan is expanding into the crypto space with its own stablecoin-like token, JPMD**, suggesting future growth and innovation potential impact on stock valuation (Source: CNBC, [June 17, 2025](https://www.cnbc.com/2025/06/17/jpmorgan-stablecoin-jpmd.html)).\n",
            "\n",
            "*Explanation*: JPMorgan's fee increase on its credit card enhances revenue potential, while moving into crypto showcases innovative growth strategies, potentially boosting investor confidence.\n",
            "\n",
            "## V\n",
            "- **Amazon and Walmart's reported exploration of stablecoin usage is discussed**, indicating potential impact on Visa and Mastercard's business but no current profit impact, according to analysts (Source: CNBC, [June 16, 2025](https://www.cnbc.com/2025/06/16/what-amazon-and-walmarts-reported-stablecoin-exploration-means-for-payments-stocks.html)).\n",
            "\n",
            "*Explanation*: Although initially not impacting profits, the integration of stablecoins by major retailers could influence Visa's future payment processing strategy and competitive positioning.\n",
            "\n",
            "## PG\n",
            "- There is no material news affecting Procter & Gamble’s stock from June 17 or June 18, 2025.\n",
            "\n",
            "*Explanation*: Procter & Gamble's stock will likely continue to be influenced by long-term business results and market trends due to absence of recent new developments.\n",
            "\n",
            "## KO\n",
            "- There is no material news affecting The Coca-Cola Company's stock from June 17 or June 18, 2025.\n",
            "\n",
            "*Explanation*: The lack of new significant events implies Coke's stock continues to react to longer-running business strategies or industry trends.\n",
            "\n",
            "## XOM\n",
            "- There is no material news affecting Exxon Mobil Corporation’s stock from June 17 or June 18, 2025.\n",
            "\n",
            "*Explanation*: With no significant recent developments, Exxon’s stock likely continues to be affected by existing scenarios related to oil prices, production levels, and broader energy markets.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def create_portfolio_breif(summary_docs:List[Document],model='gpt-4o') -> str:\n",
        "    input = f\"\"\"You are a financial analyst and expert Markdown formatter.\n",
        "\n",
        "        Your task is to synthesize the following stock-specific news briefs into a structured, markdown-formatted report. Focus only on **material information** relevant to the portfolio.\n",
        "\n",
        "        **Instructions:**\n",
        "        - Structure the output using **headings** for each portfolio stock (e.g., ## AAPL).\n",
        "        - Under each stock, use **bullet points** for each insight.\n",
        "        - Use your expert financial skill to determine what actually has a high probability to be material and only highlight those stories. Be selective!\n",
        "        - Povide a clear explaination below the news on why the news could materially affect the stock - what are the potential outcomes? \n",
        "        - Add **in-context citations** (e.g., (Source: Bloomberg, June 14)) with links to back up each point.\n",
        "        - Do **not** wrap the output in code blocks.\n",
        "        - Do **not** include commentary or filler—just structured insights.\n",
        "\n",
        "        Here are the news briefs: {str(docs)}\"\"\"\n",
        "    \n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert financial analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": input}\n",
        "        ],\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "# 3. Create and run a map-reduce summarization chain\n",
        "portfolio_brief = create_portfolio_breif(docs)\n",
        "\n",
        "print(portfolio_brief)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae218502",
      "metadata": {},
      "source": [
        "## 7. Deliver the brief\n",
        "\n",
        "We convert the Markdown to HTML and send it via Yahoo SMTP.  \n",
        "Make sure you’ve set `YAHOO_EMAIL`, `YAHOO_APP_PASSWORD`, and `TO_EMAIL` in your environment *before* running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5291d3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unhash the bwlow line if you need to install the markdown package\n",
        "#!pip install markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "9a11ab1e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Email sent successfully to brian.pisaneschi@cfainstitute.org\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import smtplib\n",
        "import markdown\n",
        "from email.message import EmailMessage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables (e.g. from a .env file)\n",
        "load_dotenv()\n",
        "\n",
        "YAHOO_EMAIL        = os.environ['YAHOO_EMAIL']\n",
        "YAHOO_APP_PASSWORD = os.environ['YAHOO_APP_PASSWORD']\n",
        "TO_EMAIL           = os.environ['TO_EMAIL']\n",
        "\n",
        "def send_yahoo_email(subject: str, body_markdown: str):\n",
        "    \"\"\"Send an HTML email via Yahoo SMTP (STARTTLS on port 587).\"\"\"\n",
        "    # Build the email\n",
        "    msg = EmailMessage()\n",
        "    msg['Subject'] = subject\n",
        "    msg['From']    = YAHOO_EMAIL\n",
        "    msg['To']      = TO_EMAIL\n",
        "\n",
        "    # Convert Markdown to HTML\n",
        "    html_body = markdown.markdown(body_markdown)\n",
        "    msg.set_content(\"This email contains HTML only.\", subtype=\"plain\")\n",
        "    msg.add_alternative(html_body, subtype=\"html\")\n",
        "\n",
        "    try:\n",
        "        # Connect, secure with STARTTLS, login, send\n",
        "        with smtplib.SMTP('smtp.mail.yahoo.com', 587, timeout=30) as server:\n",
        "            server.starttls()\n",
        "            server.login(YAHOO_EMAIL, YAHOO_APP_PASSWORD)\n",
        "            server.send_message(msg)\n",
        "        print(f\"\\n✅ Email sent successfully to {TO_EMAIL}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Failed to send: {e}\")\n",
        "\n",
        "# Example invocation using your portfolio brief\n",
        "send_yahoo_email(\"Morning Brief\", portfolio_brief)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a01bbde",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Want to Fully Automate This Workflow?\n",
        "\n",
        "If you're interested in automating this daily news briefing—complete with scheduled runs and email delivery via GitHub Actions—create a GitHub repository, clone [this](https://github.com/CFA-Institute-RPC/daily_portfolio_news_breif) repo, and follow the instructions in the [README](https://github.com/CFA-Institute-RPC/daily_portfolio_news_breif/blob/main/README.md). It walks you through setting up environment variables, customizing your portfolio, and deploying the automated workflow."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
